# 通用神经网络处理器下的核内调度问题分析

## 1. 题目总结与表述

### 1.1 背景与任务

当前的神经网络推理加速往往依赖具有**单指令多数据流**(SIMD)架构的 NPU。SIMD 架构在相同工艺下能够实现较高的单位面积计算能力，但由于神经网络算子种类繁多、拓扑结构复杂，手工编排难以适应多样任务。
 问题要求我们对**有向无环计算图(DAG)**进行核内调度：

1. **节点调度**——为所有计算节点和缓存管理节点生成满足拓扑关系的执行序列。节点包括在某执行单元上运行的操作节点和表示申请/释放缓存的管理节点。
2. **缓存分配**——对每个缓冲区(BufId)分配连续的物理地址并支持多级缓存(L1、UB、L0A/B/C)。不同缓冲区可以时间复用同一区段，但同一时刻不能重叠。
3. **SPILL 操作**——当缓存不足时，将缓冲区数据临时移出到核外 DDR 再移回，以释放空间；调度器需在计算图中插入 SPILL_OUT 与 SPILL_IN 节点并更新依赖关系。

### 1.2 优化目标

任务有三个主要优化目标：

- **最大驻留缓存需求**：给定一个调度序列 $S$，遍历序列时遇到 `ALLOC` 则驻留量增加其 `Size`，遇到 `FREE` 则减少。记最大值为 $\max(V_\text{stay})$。第一问要求在不考虑硬件限制的情况下最小化 $\max(V_\text{stay})$，即尽量缩短缓冲区生命周期，减轻内存压力。
- **总额外数据搬运量**：第二问在有限的 L1/UB/L0 容量下进行缓存分配，并通过插入 SPILL 操作解决死锁。SPILL 会导致从 DDR 读取或写回数据的额外搬运量；目标是在给定调度顺序的基础上最小化这项成本。
- **总执行时间**：第三问在不显著增加额外数据搬运量的前提下，通过优化调度顺序与缓存分配策略减少各执行单元的空闲时间，实现流水并行，降低算子的总时钟周期。

### 1.3 通俗与数学语言说明

- 通俗说明：给定一张有先后依赖的任务图，每个任务需要使用一定大小的缓存并在特定硬件单元上执行。我们需要安排这些任务的执行顺序并分配缓存空间，使得同时存放的缓存尽可能少，以减少内存压力；当缓存不足时，可将部分数据暂存到外部内存再读回，但需控制这种搬运的次数和大小；最后还希望多条硬件流水线同时工作，缩短总执行时间。

- 数学说明：令 DAG $G=(V,E)$，节点 $v\in V$ 拥有属性 $(\text{Op},\text{Pipe},\text{Cycles},\text{Size},\text{Type})$。给定一个拓扑序列 $S=(v_{i_1},v_{i_2},\ldots,v_{i_n})$，定义驻留函数
  $$
  M(v)=\begin{cases}
    \text{Size}(v), & \text{Op}(v)=\text{ALLOC},\\
    -\text{Size}(v), & \text{Op}(v)=\text{FREE},\\
    0, & \text{otherwise}.
  \end{cases}
  $$
  通过累计和计算 $V_\text{stay}(k)=\sum_{j=1}^k M(v_{i_j})$，其最大值即为调度中需要驻留的最大缓存容量；第一问目标是选择 $S$ 使 $\max_k V_\text{stay}(k)$ 最小。第二问在容量限制 $(C_{L1},C_{UB},C_{L0A},\ldots)$ 下为每个缓冲区分配地址区间，适当引入 SPILL 操作；第三问进一步在保证额外搬运量基本不增的条件下优化流水并行，最小化总完成时间。

## 2. 思路发散

### 2.1 问题1：最小缓存驻留调度的算法思路

由于**寻找最小注册/缓存压力的调度在一般 DAG 上是 NP 完全的**[arxiv.org](https://arxiv.org/pdf/2303.06855#:~:text=The min,12 nodes%2C and an arithmetic), 没有多项式时间的精确解法，我们倾向采用启发式或近似算法。以下给出几种思路：

1. **基于拓扑排序的贪心调度**：
   - 采用 Kahn 算法或 DFS 生成拓扑序，其时间复杂度为 $O(|V|+|E|)$[geeksforgeeks.org](https://www.geeksforgeeks.org/dsa/topological-sorting/#:~:text=Time Complexity%3A O(V%2BE),to creation of the stack)。
   - 在可行的多个拓扑排序中加入优先级排序：在“就绪队列”中选择下一个节点时，优先选择即将释放大量缓存或其后续使用少的节点，以尽快降低活跃缓冲区数量。类似于 register-pressure reduction 的启发式[cs.virginia.edu](https://www.cs.virginia.edu/~soffa/Soffa_Pubs_all/Conferences/Integrated.Berson.1998.pdf#:~:text=ing these demands,choice of mechanisms greatly impacts)。
   - 具体策略：为每个就绪节点计算评价函数 $f(v)=\text{释放量}/\text{需求量}$ 或 $f(v)=\text{后续最大深度}$，每次选择 $f(v)$ 最大的节点执行，从而在拓扑序列中优先安排能释放缓存的操作。
2. **基于 Sethi–Ullman 树调度的扩展**：
   - 对于表达式树，Sethi–Ullman 算法通过动态规划计算子树最大寄存器需求并确定求值顺序，从而找到最小注册压力的调度[arxiv.org](https://arxiv.org/pdf/2303.06855)。针对树结构，其时间复杂度近乎线性。
   - 对于一般 DAG，可将 DAG 拆分为树状子结构并构建“寄存器重用 DAG”，使用最大子图等价类的方法评估节点的活跃度，然后采用动态规划或分支限界求出局部最优顺序。文献指出在寄存器分配与指令调度集成算法中，**寄存器重用 DAG 能有效检测过大的并行需求并通过切分或溢出降低压力**[cs.virginia.edu](https://www.cs.virginia.edu/~soffa/Soffa_Pubs_all/Conferences/Integrated.Berson.1998.pdf#:~:text=ing these demands,choice of mechanisms greatly impacts)。
   - 这种方法适合 DAG 结构接近树形且子图较小的情况，复杂度与 DAG 的拆分和子图枚举有关，可能在最坏情况下指数级。可以采用启发式剪枝：对于复杂子图使用贪心策略，而对小规模子图使用最优解。
3. **基于整数规划或约束规划**：
   - 将节点调度时间视为决策变量，建立约束：拓扑约束、每个时间步可执行节点数为1（单线程情形）、寄存器压力约束等。在论文中，min‑reg 调度被建模为整数或约束规划问题，使用 CP-SAT 求解可得到最优解，但只有几十个节点的规模才能求解[arxiv.org](https://arxiv.org/pdf/2303.06855)。
   - 对于较大的图，可以使用基于启发式的解初始方案，再通过局部搜索或模拟退火优化。该方法求解质量高但求解时间可能较长。
4. **基于深度/宽度优先策略**：
   - 对于卷积和深层模型，深度优先和广度优先调度策略可以明显影响缓存驻留【题目文档F】。深度优先倾向先完成某一路径的计算，使其他路径的输入数据尽快释放；广度优先则让多层并行，但会积累更多中间特征在缓存中。
   - 可以针对不同算子（Conv/Matmul/Attention）设计经验性顺序，例如卷积层使用深度优先以降低中间特征驻留，矩阵乘用分块交叉顺序【题目文档F】。

### 2.2 问题2：缓存分配与换入换出策略

当调度顺序固定时，缓存分配问题等价于**在线区间染色**。常见思路如下：

1. **首次适配/最佳适配策略**：维持每种缓存类型的空闲区间列表，遇到 `ALLOC` 申请时按“首适配”或“最佳适配”选择一个能容纳其 `Size` 的区间。如果无可用区间，则考虑释放已分配但已不再使用的缓冲区，或引发 SPILL 操作。
2. **生命周期压缩与重叠分析**：在分配之前分析每个缓冲区的活跃区间 $(s_i,e_i)$，通过排序使不重叠或短生命周期的缓冲区分配到相同地址，提高空间复用。动态分配时使用二分木或优先队列快速查询。
3. **SPILL 策略**：当空闲空间不足时，挑选一个缓冲区 b 进行 SPILL：插入 `SPILL_OUT(b)` 将其内容写回 DDR 并释放其区间，在需要再次使用时在 `SPILL_IN(b)` 前为其分配新地址。根据缓冲区大小、下次使用时间和是否由 `COPY_IN` 生成等因素排序选择 SPILL 对象：优先选择容量大、下次使用最晚或可从 DDR 直接加载的缓冲区。文献指出采用**自底向上优先级**或**寄存器压力检测**机制选择溢出对象能有效降低溢出量[cs.virginia.edu](https://www.cs.virginia.edu/~soffa/Soffa_Pubs_all/Conferences/Integrated.Berson.1998.pdf#:~:text=ing these demands,choice of mechanisms greatly impacts)。
4. **利用多级缓存**：L0A/B/C 只能同时驻留一个缓冲区，需尽快释放；L1、UB 容量大但有限。优先将短生命周期的数据放在高层缓存；长生命周期或在多个阶段反复使用的数据放在 UB，并尽可能避免频繁来回搬运。结合分块矩阵乘和注意力算子的特性，可以在行内复用矩阵块[arxiv.org](https://arxiv.org/html/2503.22365v1#:~:text=context%2C we have designed three,constraints when scheduling workflow tasks)。

### 2.3 问题3：总执行时间优化策略

总执行时间受执行单元串行依赖和资源独占约束影响，优化策略包括：

1. **流水化与并行化**：不同执行单元(如 MTE、Cube、Vector)可以同时工作，只要依赖满足。可以采用类似 HEFT（Heterogeneous Earliest Finish Time）的策略：为每个就绪节点计算在各单元上的最早可开始时间，根据**底层层次(critical path)\**和\**最早完成时间**决定调度顺序。内存感知的 HEFT 变体通过底层优先或最小内存遍历产生更短的执行时间或更低的内存占用[arxiv.org](https://arxiv.org/html/2503.22365v1#:~:text=context%2C we have designed three,constraints when scheduling workflow tasks)。
2. **合并与拆分操作**：多个连续的同类操作(如多个 COPY_IN)可合并以减少调度节点数量；对于长周期操作可拆分为更小的子块，在 Cube 和 Vector 核之间交错执行，实现流水并行。例如矩阵乘分块顺序采用“之字形”路径，可以减少 B 矩阵块的重复加载，降低数据搬运量并平衡各单元负载【题目文档F】。
3. **空闲时间填充**：当某单元空闲且缓存足够时，可以提前执行后续无依赖的 COPY_IN 或预取操作，让数据提前进入缓存，减少后续等待时间。动态调整任务优先级使各单元尽量保持忙碌。
4. **调整调度顺序**：在问题 2 的基础上，对调度顺序进行局部交换或重排序，评估其对额外搬运量和执行时间的影响。可以采用基于模拟退火的局部搜索，在不增加搬运量的前提下优化流水时隙利用率。

## 3. 算法设计

### 3.1 问题1算法设计

我们设计两种代表性算法：**贪心拓扑调度**和**动态规划+局部搜索**。

#### 3.1.1 贪心拓扑调度算法

**输入**：计算图 $G=(V,E)$，每个节点的 `Op`、`Size` 等属性。

**处理过程**：

1. 统计每个节点的入度值，初始化就绪集合 $R$ 为入度为0的节点。设驻留容量累积变量 $V_{\text{stay}}=0$，记录当前驻留缓冲区集合 $\mathcal{L}$。
2. 在每一步，从就绪集合 $R$ 中选择一个节点 $v$ 执行，选择标准如下：
   - 若 $v$ 为 `FREE`，执行后会释放缓存，优先级最高；
   - 其次选择 `ALLOC` 节点，其所分配的缓冲区尺寸小；
   - 其他节点按照启发函数 $f(v)$ 排序，例如 $f(v)=-\text{size of live buffers after执行}$，或选取后续依赖层级较浅的节点。类似于寄存器压力减少启发式[cs.virginia.edu](https://www.cs.virginia.edu/~soffa/Soffa_Pubs_all/Conferences/Integrated.Berson.1998.pdf#:~:text=ing these demands,choice of mechanisms greatly impacts)。
3. 执行节点 $v$ 后更新 $V_{\text{stay}}$：若为 `ALLOC` 则加上 `Size`，加入 $\mathcal{L}$；若为 `FREE` 则减去对应 `Size` 并从 $\mathcal{L}$ 中移除；其他节点不改变驻留。
4. 将 $v$ 出边所指节点的入度减一，若入度减为 0，则加入 $R$。重复步骤 2–4 直至所有节点执行完。
5. 记录 $V_{\text{stay}}$ 的最大值即为调度序列的驻留需求。

**输出**：调度序列 $S$ 与其对应的 $\max(V_\text{stay})$。

**时间复杂度分析**：拓扑排序过程需要遍历每条边及选择节点。采用优先队列存储就绪节点，更新和选择操作成本为 $O(\log|V|)$，总复杂度为 $O(|V|\log|V| + |E|)$，与经典拓扑排序 $O(V+E)$ 相近[geeksforgeeks.org](https://www.geeksforgeeks.org/dsa/topological-sorting/#:~:text=Time Complexity%3A O(V%2BE),to creation of the stack)。启发函数计算需要额外的常数开销。

**优缺点**：算法简单、快速，适用于大规模计算图，但结果质量依赖于启发函数，可能无法达到最优。适合在线调度或大量实例场景。

#### 3.1.2 动态规划 + 局部搜索算法

**核心思想**：将计算图划分为多个近似树形的子图，对每个子图采用 Sethi–Ullman 动态规划获得最小驻留顺序，再将子图拼接；对拼接部分通过局部交换与分支限界搜索优化。

**步骤**：

1. **子图提取**：使用图分割或社区发现算法将 DAG 划分为若干子图，每个子图节点数较小且结构接近树。对于树形子图，使用扩展的 Sethi–Ullman 算法计算最优顺序；对非树部分采用贪心策略。
2. **初始合并**：按拓扑顺序将各子图的调度序列串联，并在合并处考虑依赖关系重新排序。
3. **局部搜索优化**：对合并后的序列进行局部交换（例如相邻的非依赖节点交换顺序），计算新的 $\max(V_{\text{stay}})$。若减少驻留则接受，直到无法改进。也可以采用模拟退火或 Tabu 搜索探索更大范围的交换。

**时间复杂度分析**：动态规划在树形子图上复杂度为 $O(n)$；局部搜索涉及多次遍历序列，每次交换开销 $O(1)$，总次数取决于搜索轮数。整体复杂度大于贪心，但对于有明显层次结构的图可获得较优解，尤其适用于深度较浅、依赖复杂的算子，如卷积网络。

**优缺点**：解的质量更高，但实现复杂且求解时间较长。适合节点规模中等、具有分块结构的计算图（如 FlashAttention 分块、Matmul 分块）。

### 3.2 问题2算法设计（缓存分配与 SPILL）

在获取调度序列后，需要为每个缓冲区分配物理地址，并在空间不足时进行 SPILL。下面给出一种基于区间分配与优先级溢出的策略。

**输入**：调度序列 $S$，每个缓冲区的 `Size`、`Type` 及其生命周期 $(s_i,e_i)$。硬件缓存容量 $C_{L1},C_{UB},\ldots$。

**处理过程**：

1. **区间排序**：按缓冲区生命周期的开始时间 $s_i$ 升序排序。当遍历到缓冲区 $i$ 的 `ALLOC` 时，尝试在其所属 `Type` 的空闲区间列表中找到长度不小于 `Size_i` 的区间。空闲区间列表可用平衡树表示，查询和插入复杂度 $O(\log n)$。
2. **首次或最佳适配**：优先选择最小可容纳的区间，减少碎片。如果有多个可用区间，选择首适配即可；若无可用区间，则触发 SPILL 过程。
3. **SPILL 选择**：从当前驻留的缓冲区集合中选择一个或多个作为 SPILL 对象，插入 `SPILL_OUT` 与 `SPILL_IN` 节点。选择策略依据：
   - 缓冲区的下次使用时间最晚(希望后面再读回)。
   - 缓冲区大小较大或可直接通过 `COPY_IN` 加载(只需 `SPILL_IN`，额外搬运量小)。
   - 避免即将使用的缓冲区和处于 L0A/B/C 的缓冲区。
4. **更新数据结构**：执行 SPILL_OUT 时，将被选缓冲区的区间加入空闲列表，记录其新偏移地址为 DDR。执行 SPILL_IN 时，为其重新分配缓冲区，可能放在不同的地址。
5. **记录额外搬运量**：根据是否需要两次 DDR 访问，累计额外数据搬运量。若缓冲区未由 `COPY_IN` 使用，则 SPILL_OUT 和 SPILL_IN 都会访问 DDR，额外搬运量为 $2\times \text{Size}$，否则只记录一次搬入【题目文档附录C】。
6. **生成调度序列**：将 SPILL 节点插入原调度序列相应位置，更新依赖关系，输出新的完整序列以及每个缓冲区的偏移地址。

**输出**：`schedule.txt`：插入 SPILL 后的完整调度顺序；`memory.txt`：每个缓冲区的物理偏移；`spill.txt`：每次 SPILL 操作的目标缓冲区和新偏移。

**时间复杂度分析**：遍历缓冲区分配时，每个缓冲区分配和释放各涉及 $O(\log n)$ 的区间插入/删除，总复杂度 $O(n\log n)$。SPILL 的选择需扫描驻留集合，可维护一个按下次使用时间排序的堆以 $O(\log n)$ 获取候选。整体复杂度近似 $O(n\log n)$。

**优缺点**：该方法简单易实现，能在多数情况下减少 SPILL 次数。缺点是过于贪心，无法保证全局最优。对于高度动态的生命周期，可能需要更复杂的策略，如动态调整调度顺序或将大缓冲区拆分为更小块。

### 3.3 问题3算法设计（运行时间优化）

在第二问的基础上，为降低总执行时间，需充分利用多执行单元的并行性。下面给出基于 HEFT 的流水化调度及局部调整策略。

**输入**：含 SPILL 的完整计算图 $G'=(V',E')$，每个节点的 `Pipe`、`Cycles`、`Type` 等属性，缓存分配结果。

**处理过程**：

1. **计算关键路径与代价**：对于每个节点 $v$，计算其在 DAG 上的**底层** $b(v)$——从 $v$ 出发到终点的最长路径长度(以执行时间衡量)。底层较大的节点对总体完成时间影响更大。
2. **初始化就绪列表**：将所有入度为0的节点加入就绪列表；对每个节点计算在对应 `Pipe` 上的最早可开始时间 $\mathrm{EST}(v)$，结合资源占用情况。
3. **调度选择策略**：按照类似 HEFT 的原则，从就绪列表中选择具有最大底层值或最小完成时间的节点并分发到对应的执行单元，同时更新各单元的可用时间。为了考虑内存约束，可在选择时忽略其需要等待缓存释放的节点。
4. **预取与提前执行**：当某单元空闲并且后续任务的依赖已满足且缓存空间足够时，提前执行其 `COPY_IN` 或 `ALLOC` 节点，使数据提前到达缓存。这样可以在后续计算阶段减少等待，提高流水并行。该策略类似于**Eviction heuristics**中“先加载数据块，后计算”的做法[arxiv.org](https://arxiv.org/html/2503.22365v1#:~:text=context%2C we have designed three,constraints when scheduling workflow tasks)。
5. **局部重排与平衡**：在不改变内存分配和额外搬运量的条件下，对调度序列中连续的无依赖节点在不同执行单元之间交换顺序，使得所有单元的负载更均衡。例如将某 Cube 单元长周期计算节点与 MTE 单元短周期节点互换，从而减少单元空闲时间。利用模拟退火或贪心插入算法寻找更优顺序。

**输出**：优化后的调度顺序和计算的总执行时间。可在论文中通过绘制时序流水图展示各单元的工作状态。

**复杂度分析**：HEFT 原算法的复杂度为 $O(|V|^2)$，通过优化数据结构可降至 $O(|V|\log |V|)$。局部交换需要重新计算影响的节点开始时间，开销较大，因此可限制交换次数或仅考虑交换度较小的邻近节点。

**优缺点**：该方法能显著降低总执行时间，但实现复杂，需要准确估计节点耗时和缓冲区状态。对依赖复杂或周期分布不均的图很有效，尤其适用于 FlashAttention 等具有交替的 Cube 和 Vector 单元的任务。

## 4. 结果输出说明

### 4.1 运行算法的步骤

对于提供的 JSON 或 CSV 格式的示例计算图，可按照以下流程运行所设计的算法：

1. **读取并解析图**：从 `<任务名>.json` 中读取 `Nodes` 和 `Edges`，构建节点属性表和邻接表。对 CSV 文件，同理解析。
2. **求解问题1**：根据选定的调度算法（如贪心拓扑或动态规划+局部搜索），计算一个含所有节点的调度序列 $S$，并记录 `ALLOC`/`FREE` 的最大驻留值。将结果保存为 `<任务名>_schedule.txt`，一行一个节点 Id。
3. **求解问题2**：在固定调度序列 $S$ 或调整后的序列基础上，按第 3.2 节算法进行缓存分配和 SPILL 插入。保存：
   - `<任务名>_schedule.txt`：包含原节点及 SPILL 节点的完整执行顺序；
   - `<任务名>_memory.txt`：每行“BufId:Offset”；
   - `<任务名>_spill.txt`：每行“BufId:NewOffset”，顺序与调度序列中 SPILL 操作一致。
4. **求解问题3**：在第二问结果基础上，通过流水化调度优化顺序，记录优化前后的总执行时间和额外搬运量变化，并生成同样格式的输出文件。

### 4.2 结果趋势预测

根据不同算子的特性，可预判算法的难度：

- **Matmul**：计算图呈块矩阵乘的四阶段模式，缓冲区的生命周期较短，数据复用主要在 B 矩阵块。若采用“之字形”分块顺序可减少 B 块的重复加载【题目文档F】。由于缓冲块较规则，贪心调度能得到较小的最大驻留，但若分块过多，内存约束仍可能触发 SPILL。
- **FlashAttention**：包含 Cube 和 Vector 两类子图，每个分块计算涉及 Q、K、V 矩阵的复用。调度需要在 Cube 与 Vector 单元间交替执行以实现流水并行【题目文档F】。由于 Softmax 和 PostUpdate 部分产生的缓冲区在多个子阶段间传递，生命周期较长，容易出现内存瓶颈，需采用更精细的缓存分配。
- **Conv**：卷积网络层间的输入特征图可能非常大，深度优先策略可以释放上一层的输出，减少驻留；广度优先可能导致大量中间特征驻留。卷积核较小且可快速释放，因此针对 Conv 任务通常不会产生过多 SPILL，但总执行时间受到层间依赖的影响，需要流水化优化。

## 5. 论文写作建议

### 5.1 论文结构框架

一份完整的参赛论文应包含以下部分：

1. **摘要**：简洁概括问题背景、主要贡献、所提出的算法和实验结果。
2. **引言**：阐述核内调度的意义、现有瓶颈、研究动机以及本文的创新点。简述问题一二三的任务目标和挑战。
3. **相关工作**：综述指令调度、寄存器分配与内存感知调度的相关研究。可引用文献指出 min‑reg 调度问题的 NP‑完全性以及寄存器重用 DAG 与 live‑range splitting 在降低寄存器压力上的作用[cs.virginia.edu](https://www.cs.virginia.edu/~soffa/Soffa_Pubs_all/Conferences/Integrated.Berson.1998.pdf#:~:text=ing these demands,choice of mechanisms greatly impacts)。
4. **模型建立**：从硬件抽象和计算图定义出发，给出数学模型，定义节点属性、依赖关系、缓冲区生命周期、目标函数等。描述 SPILL 机制和多级缓存的容量约束。
5. **算法设计**：分节介绍问题1、问题2、问题3的具体算法。可使用伪代码、流程图或公式展示算法逻辑，并分析时间复杂度。讨论启发式的设计思想和适用场景。
6. **实验设计与结果分析**：详细描述实验环境、数据集(示例计算图)、算法参数。报告调度序列的最大驻留值、SPILL 数量、总额外数据搬运量和总执行时间等指标。可绘制流水图以直观展示优化效果。分析不同算子上算法表现的差异及原因，讨论贪心策略与动态规划的优劣。
7. **结论与展望**：总结工作亮点，指出算法在实际部署中的潜在价值，并讨论尚未解决的问题，如对更复杂网络结构的适应性、算法在硬件实验中的验证等。

### 5.2 模型建立与实验分析写作模板

**模型建立示例**：

> 为了对 NPU 核内调度问题进行建模，本文将计算图 $G=(V,E)$ 中的每个节点抽象为在特定执行单元上的一条指令，依赖关系为有向边。令 $S=(v_{i_1},\dots,v_{i_n})$ 表示一条满足拓扑约束的调度序列。定义缓冲区集合 $\mathcal{B}$ 和生命周期区间 $(s_b,e_b)$。目标是在满足节点依赖及缓存容量限制的前提下，最小化最大驻留缓存 $\max_k \sum_{b\in\mathcal{B}} M_b(k)$、总额外搬运量 $D(\text{SPILL})$ 以及总执行时间 $T(\text{schedule})$。其中 $M_b(k)$ 表示调度到第 $k$ 步时缓冲区 $b$ 是否驻留在缓存。该问题是多目标优化，可通过分阶段或加权方式求解。

**实验分析示例**：

> 在实验部分，我们首先比较贪心拓扑调度与动态规划+局部搜索在六个示例计算图上的表现。表 **1** 汇报了各算子类型的节点数、边数、最大驻留需求和溢出次数。对于 `Matmul_Case1`，贪心算法取得的最大驻留值为 **X**，动态规划算法为 **Y**，后者降低了 **Z%** 的驻留需求。接着在固定调度顺序下应用区间分配策略，测量总额外数据搬运量和 SPILL 次数。图 **2** 给出了对 `FlashAttention_Case0` 的流水图，展示了 Cube 和 Vector 单元的交替执行以及通过提前 COPY_IN 减少空闲时间的效果。最后，我们评估了在不显著增加搬运量的条件下，总执行时间优化策略带来的改进：在 `Conv_Case1` 上，优化前总周期为 **A**，优化后为 **B**，提升约 **C%**。

这样的模板帮助读者清楚了解算法模型假设、实验设置和结果解读。